# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import sys
import time

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import streamlit as st

# sys.path ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'Main')))

# ë‚´ë¶€ ëª¨ë“ˆ
from sidebar import render_history_sidebar
from model_Frontend_v3 import classify_legal_issue, load_model
from ui_components import (
    render_user_input,
    render_user_message,
    render_assistant_message,
    render_assistant_message_stream,
    render_title_image,
    render_raw_info,
)
from action_guide import action_guide_agent
from law_info_ExceptDB import get_law_info


################################################################################
################################ Page Config ###################################
################################################################################


# Page Config êµ¬ì„±
st.set_page_config(
    page_title="Streamly - An Intelligent Streamlit Assistant",
    page_icon="imgs/avatar_streamly.png",
    layout="wide",
    initial_sidebar_state="auto",
    menu_items={
        "Get Help": "https://github.com/khj200013/OpenA1/issues",
        "Report a bug": "https://github.com/khj200013/OpenA1/issues",
        "About": """
            ## AIë¥¼ í†µí•´ ê°œì¸ì •ë³´ ë³´í˜¸ë²•ì— ìœ„ë°°ë˜ëŠ” ì‚¬í•­ í™•ì¸
            ### Powered using GPT-4

            **GitHub**: https://github.com/khj200013/OpenA1
            **ë¬¸ì˜ ë˜ëŠ” ë²„ê·¸ ì œë³´**: [Issue ë“±ë¡í•˜ê¸°](https://github.com/khj200013/OpenA1/issues)

            ì´ AI ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” ì‚¬ìš©ìì˜ ìƒí™©ì´ë‚˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ  
            **ê°œì¸ì •ë³´ë³´í˜¸ë²• ë˜ëŠ” ê´€ë ¨ ê·œì •(GDPR ë“±)**ì— ë”°ë¼  
            ìœ„ë°˜ ê°€ëŠ¥ì„±ì„ ë¶„ì„í•˜ê³ , ê´€ë ¨ ë²•ë ¹ê³¼ ëŒ€ì‘ ë°©ì•ˆì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

            Image created by OpenAI
        """
    }
)


################################################################################
################################ GPT UI êµ¬ì„± ###################################
################################################################################


# ë¡œê³  ì´ë¯¸ì§€ ì¶œë ¥
render_title_image()

# ëª¨ë¸ ë¡œë”©
if "model_loaded" not in st.session_state:
    tokenizer, model = load_model()
    st.session_state.tokenizer = tokenizer
    st.session_state.model = model
    st.session_state.model_loaded = True


if 'openai_model' not in st.session_state:
    st.session_state.openai_model = 'gpt-4.1'

if 'messages' not in st.session_state:
    st.session_state.messages = []


# ê¸°ì¡´ ë©”ì‹œì§€ ì¶œë ¥
for i, msg in enumerate(st.session_state.messages):
    if msg["role"] == "system":
        continue  
    if msg["role"] == 'user':
        render_user_message(msg["content"])
    elif  msg["role"] == 'assistant': 
        if msg["law_info"]:
            render_raw_info(msg["law_info"])
        render_assistant_message(msg["predicted_label"], msg["content"])


# ì‚¬ìš©ì ì…ë ¥ ì €ì¥ í›„ rerun ì²˜ë¦¬ (stream ì¤‘ ì…ë ¥ ë°©ì§€)
if "user_input" not in st.session_state:
    if prompt := render_user_input():
        st.session_state.user_input = prompt
        st.rerun()

# GPT ì‘ë‹µ ì²˜ë¦¬
if "user_input" in st.session_state:
    prompt = st.session_state.user_input
    # ì‚¬ìš©ì ë©”ì‹œì§€ session_stateì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ìœ ì € ë©”ì‹œì§€ ë Œë”
    render_user_message(prompt)

    # ë¼ë²¨ ë¶„ë¥˜
    predicted_label = classify_legal_issue(prompt, st.session_state.tokenizer, st.session_state.model)

    # GPT PROMPT
    with st.spinner("ğŸ” ë²•ë¥  ì •ë³´ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        law_info = get_law_info(predicted_label, prompt)
    render_raw_info(law_info)


    response_stream = action_guide_agent(prompt, predicted_label)

    # AI ë©”ì‹œì§€ ë Œë” (Stream í˜•íƒœ)
    response_text = render_assistant_message_stream(predicted_label, response_stream)
    
    # AI ë©”ì‹œì§€ session_stateì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", 
                                      "predicted_label": predicted_label, 
                                      "law_info" : law_info,
                                      "content": response_text})
    # ì§ˆë¬¸ + ë‹µë³€ ì €ì¥
    st.session_state.history[predicted_label].append({
        "question": prompt,
        "answer": response_text
    })
    
    # user_input ì‚­ì œ í›„ rerun
    del st.session_state.user_input
    st.rerun()

################################################################################
################################[ ì‚¬ ì´ ë“œ ë°” ]#################################
################################################################################

# íˆìŠ¤í† ë¦¬ìš© ë”•ì…”ë„ˆë¦¬
if "history" not in st.session_state:
    st.session_state.history = {
        "ì´ˆìƒê¶Œ ì¹¨í•´": [],
        "ë™ì˜ ì—†ëŠ” ê°œì¸ì •ë³´ ìˆ˜ì§‘": [],
        "ëª©ì  ì™¸ ì´ìš©": [],
        "ì œ3ì ë¬´ë‹¨ ì œê³µ": [],
        "CCTV ê³¼ì‰ì´¬ì˜": [],
        "ì •ë³´ ìœ ì¶œ": [],
        "íŒŒê¸° ë¯¸ì´í–‰": [],
        "ê´‘ê³ ì„± ì •ë³´ ìˆ˜ì‹ ": [],
        "ê³„ì •/ë¹„ë°€ë²ˆí˜¸ ê´€ë ¨ ë¬¸ì œ": [],
        "ìœ„ì¹˜ì •ë³´ ìˆ˜ì§‘/ìœ ì¶œ": [],
        "ê°œì¸ì •ë³´ ì—´ëŒÂ·ì •ì • ìš”êµ¬ ê±°ë¶€": []
    }

render_history_sidebar()

